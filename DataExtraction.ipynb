{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### functionality"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "Purpose: extracts useful information from each offline solution in \"Observational Data\" directory and transfers into various separate CSV files for further processing.\n",
    "\n",
    "Approach: open and prepare all input files (Antenna.xml, Station.xml, Weather.xml, CalPhase.xml, *_tc_antpos.log) for looping.\n",
    "\n",
    "Notes: Antenna.xml provides antenna with corresponding station names; Station.xml provides pad names with corresponding station names, and geocentric pad positions; Weather.xml provides six weather attributes; CalPhase.xml provides phase data; *_tc_antpos.log provides poserr, poserr(), newpos, and geopos data."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### required directory structure"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "-> \"Offset Drift\" directory\n",
    "    -> \"Observational Data\" directory\n",
    "        -> M_DD_YYYY directory\n",
    "            -> \"ASDMs\" directory\n",
    "                -> uid___* directories\n",
    "                    -> at least \"Antenna.xml\", \"Station.xml\", \"Weather.xml\", \"ASDM.xml\", *_tc_antpos.log\n",
    "    -> \"Packages\" directory\n",
    "        -> \"Miscellaneous.py\"\n",
    "        -> \"TimeConvert.py\"\n",
    "    -> \"DataExtraction.ipynb\"/\"DataExtraction.py\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### input initialization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirName = 'M_DD_YYYY' # Name of \"Observational Data\" subdirectory to be created, usually of the format M_DD_YYYY\n",
    "\n",
    "refants = ['DA59','DV11','DA49','DV12','PM01','DV07'] # Can be any number of antenna names, though plots generally\n",
    "                                                      # require six. Order doesn't matter\n",
    "\n",
    "gendir = '/.../Offset Drift/Observational Data/' # \"Observational Data\" location, assuming specified structure"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "subdirName = '8_9_2021' # Name of \"Observational Data\" subdirectory to be created, usually of the format M_DD_YYYY.\n",
    "\n",
    "refants = ['DA59','DV11','DA49','DV12','PM01','DV07'] # Can be any number of antenna names, though plots generally\n",
    "                                                      # require six. Order doesn't matter.\n",
    "\n",
    "gendir = '/Users/colemeyer/Documents/Offset Drift/Observational Data/' # \"Observational Data\" location, assuming specified structure."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "ename": "ModuleNotFoundError",
     "evalue": "No module named 'Packages'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mModuleNotFoundError\u001b[0m                       Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-7-a438011e79e6>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m#import numpy as np\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m#import pandas as pd\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0;32mfrom\u001b[0m \u001b[0mPackages\u001b[0m \u001b[0;32mimport\u001b[0m \u001b[0mMiscellaneous\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0mmc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;31m#from Packages import TimeConvert as tc\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mModuleNotFoundError\u001b[0m: No module named 'Packages'"
     ]
    }
   ],
   "source": [
    "import os\n",
    "#import re\n",
    "#import numpy as np\n",
    "#import pandas as pd\n",
    "from Packages import Miscellaneous as mc\n",
    "#from Packages import TimeConvert as tc"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Data Extraction from ASDMs in \"Observational Data\" subdirectory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nnumObs = mc.numObs(genDir)\\n\\nfor uid in os.listdir(genDir):\\n    if uid[:3] == \"uid\":\\n        uidDir = genDir+uid+\\'/\\'\\n\\n        # Open all input files from offline solution\\n        antXML = open(uidDir+\\'Antenna.xml\\',\"r\")\\n        statXML = open(uidDir+\\'Station.xml\\',\"r\")\\n        weaXML = open(uidDir+\\'Weather.xml\\',\"r\")\\n        phaseXML = open(uidDir+\\'CalPhase.xml\\',\"r\")\\n        for file in os.listdir(uidDir):\\n            if \".log\" in file:\\n                log = open(uidDir+file,\"r\")\\n\\n        # Create all pre-CSV arrays\\n        antArr = np.empty((1,21),dtype=\\'U25\\')\\n        weaArr = np.empty((1,11),dtype=\\'U25\\')\\n\\n        # Prepare all input files for looping\\n        ##########\\n        line = antXML.readline()\\n        while \"<ContainerEntity\" not in line:\\n            line = antXML.readline()\\n        ##########\\n        line = statXML.readline()\\n        while \"<ContainerEntity\" not in line:\\n            line = statXML.readline()\\n        ##########\\n        line = weaXML.readline()\\n        while \"<ContainerEntity\" not in line:\\n            line = weaXML.readline()\\n        ##########\\n        line = phaseXML.readline()\\n        while \"<ContainerEntity\" not in line:\\n            line = phaseXML.readline()\\n        ##########\\n        line = log.readline()\\n        while \"Ref.\" not in line:\\n            line = log.readline()\\n        ##########\\n\\n\\n        ########## Antenna.xml Cycling\\n        line = antXML.readline()\\n        while \"</AntennaTable>\" not in line:\\n            antXML.readline()\\n\\n            antRow = np.empty(21,dtype=\\'U25\\')\\n            antRow[0] = re.sub(r\"<.*?>\", \"\", antXML.readline()).strip() # antname\\n            for i in range(6): line = antXML.readline()\\n            antRow[2] = re.sub(r\"<.*?>\", \"\", antXML.readline()).strip() # statnum\\n            for i in range(2): line = antXML.readline()\\n\\n            antArr = np.vstack((antArr,antRow)) # Add row to antArr\\n\\n        antArr = antArr[1:,:] # Remove first row (consequence of row-adding method)\\n\\n\\n        ########## Station.xml Cycling\\n        row = 0\\n        line = statXML.readline()\\n        while \"</StationTable>\" not in line:\\n            if row < np.shape(antArr)[0]:\\n                statXML.readline()\\n\\n                antArr[row,1] = re.sub(r\"<.*?>\", \"\", statXML.readline()).strip() # padname\\n                line = statXML.readline().split()\\n                for i in range(2,4): antArr[row,i+15] = line[i] # geopos (X,Y)\\n                antArr[row,19] = line[4].rstrip(\"</position>\\n\") # geopos (Z)\\n                for i in range(3): line = statXML.readline()\\n            else:\\n                weaRow = np.empty(11,dtype=\\'U25\\')\\n                weaRow[1] = re.sub(r\"<.*?>\", \"\", statXML.readline()).strip() # statnum\\n                weaRow[0] = re.sub(r\"<.*?>\", \"\", statXML.readline()).strip() # padname\\n                line = statXML.readline().split()\\n                for i in range(2,4): weaRow[i] = line[i] # geopos (X,Y)\\n                weaRow[4] = line[4].rstrip(\"</position>\\n\") # geopos (Z)\\n                for i in range(3): line = statXML.readline()\\n\\n                weaArr = np.vstack((weaArr,weaRow)) # Add row to weaArr\\n\\n            row += 1\\n\\n        weaArr = weaArr[1:,:] # Remove first row (consequence of row-adding method)\\n\\n\\n        ########## Weather.xml Cycling\\n        tempWeaArr = np.zeros((len(weaants),7),dtype=\\'float\\')\\n\\n        line = weaXML.readline()\\n        while \"</WeatherTable>\" not in line:\\n            line = weaXML.readline()\\n\\n            temp = np.empty(6,dtype=\\'float\\')\\n            for i in range(6): temp[i] = re.sub(r\"<.*?>\", \"\", weaXML.readline()).strip() # All weather attributes\\n            statNum = weaXML.readline().lstrip(\"    <stationId>\").rstrip(\"</stationId>\\n\")\\n            for i in range(2): line = weaXML.readline()\\n\\n            \\n            The strategy below is a bit tricky. Since it\\'s tricky adding rows to 3D numpy arrays, I\\'ve decided to\\n            implement a sort of working average concept. The idea is that tempWeaArr has len(weaants) rows, each \\n            with 7 columns. These 7 columns are the 6 weather attributes plus the \"number of rows\" so that we can \\n            take the average correctly. For each chunk of weather data for a given station in Weather.xml, the \\n            working average is updated along with the \"number of rows\".\\n            \\n\\n            for i in range(len(weaants)):\\n                if weaArr[i,1] == statNum and temp[0] != 0:\\n                    tempWeaArr[i,:6] = tempWeaArr[i,:6] + temp # Summation portion of \"working average\"\\n                    tempWeaArr[i,6] += 1\\n\\n        for row in range(np.shape(tempWeaArr)[0]):\\n            if tempWeaArr[row,6] != 0:\\n                tempWeaArr[row,:6] = tempWeaArr[row,:6] / tempWeaArr[row,6] # Division portion of \"working average\"\\n\\n        for i in range(len(weaants)):\\n            for j in range(6):\\n                weaArr[i,5:] = tempWeaArr[i,:6]\\n\\n        ########## CalPhase.xml Cycling\\n        line = phaseXML.readline()\\n        while \"<singleAntennaName>\" not in line: line = phaseXML.readline()\\n        line = re.sub(r\"<.*?>\", \"\", line).strip().split()\\n\\n        antNames = []\\n        for i in range(2,int(line[1])+2): antNames.append(line[i][1:-1])\\n\\n        phaseXML = open(uidDir+\\'CalPhase.xml\\',\"r\")\\n        phaseData = np.zeros((len(antNames),3),dtype=\\'float\\')\\n\\n        for i in range(5): line = phaseXML.readline()\\n        while \"</CalPhaseTable>\" not in line:\\n            for i in range(108): phaseXML.readline() # Skips BB_1, BB_2, BB_3, and BB_4 entirely\\n            for i in range(21): phaseXML.readline() # Skips to phaseAnt data within BB_ALL\\n\\n            line = re.sub(r\"<.*?>\", \"\", phaseXML.readline()).strip().split()\\n\\n            \\n            I\\'ve decided to adopt the same \"working average\" concept above here, since the data comes in a\\n            similar format.\\n            \\n\\n            # Processing <phaseAnt> data within BB_ALL\\n            temp = line[2]\\n            line = line[3:]\\n            for j in range(2):\\n                for i in range(int(j*len(line)/2),int((j+1)*len(line)/2)):\\n                    if line[i] != 0:\\n                        phaseData[int(i%(len(line)/2)),j] = phaseData[int(i%(len(line)/2)),j] + float(line[i]) # Summation portion of \"working average\"\\n            phaseData[:,2] += 1\\n\\n            for i in range(5): line = phaseXML.readline()\\n\\n        for i in range(2): phaseData[:,i] = phaseData[:,i] / phaseData[:,2] # Division portion of \"working average\"\\n        phaseData = phaseData[:,:2]\\n\\n        antArr[:,3:5] = phaseData[:,:]\\n\\n\\n        ########## .Log Cycling\\n        row = 1\\n        line = log.readline()\\n        while row < np.shape(antArr[:,0])[0]:\\n            line = line.split()\\n            for i in range(3): antArr[row,i+5] = line[2*(i+2)] # poserr (X,Y,Z)\\n            for i in range(2): antArr[row,i+8] = line[2*(i+3)-1][1:-3] # poserr() (X,Y)\\n            antArr[row,10] = line[9][1:-2] # poserr() (Z)\\n            antArr[row,20] = line[12]\\n            line = log.readline().split()\\n            for i in range(3): antArr[row,i+11] = line[2*(i+1)] # newpos (X,Y,Z)\\n            line = log.readline().split()\\n            for i in range(3): antArr[row,i+14] = line[2*(i+1)] # geoerr (X,Y,Z)\\n            for i in range(2): line = log.readline()\\n\\n            row += 1\\n\\n        weaArr[weaArr == \"0.0\"] = np.nan\\n        antArr[antArr == \"0.0\"] = np.nan\\n        antArr[antArr == \"\"] = np.nan\\n        pd.DataFrame(weaArr).to_csv(uidDir+\\'WeaData.csv\\', index=None, header=weaArrHeaders) # Export weaArr to WeaData.csv\\n        pd.DataFrame(antArr).to_csv(uidDir+\\'AntData.csv\\', index=None, header=antArrHeaders) # Export antArr to AntData.csv\\n'"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# May need to be updated eventually. Must include all weather stations that appear in Weather.xml\n",
    "weastats = ['Meteo129','Meteo130','Meteo131','Meteo201','Meteo309','Meteo410','MeteoCentral','MeteoItinerant']\n",
    "\n",
    "gendir = gendir+subdirName+'/ASDMs/'\n",
    "\n",
    "antArrHeaders = ['antname','padname','statnum','xPhaseAvg','yPhaseAvg','poserrX','poserrY','poserrZ','poserr()X','poserr()Y','poserr()Z','newposX','newposY','newposZ','geoerrX','geoerrY','geoerrZ','geoposX','geoposY','geoposZ','delayrms']\n",
    "weaArrHeaders = ['padname','statnum','geoposX','geoposY','geoposZ','pressure','relHum','temp','windDir','windSpeed','windMax']\n",
    "\n",
    "numObs = mc.numObs(gendir)\n",
    "\n",
    "for ASDM in os.listdir(gendir):\n",
    "    if \"uid\" in ASDM:\n",
    "        asdmdir = gendir+ASDM+'/'\n",
    "\n",
    "        # Open all input files from offline solution\n",
    "        antXML = open(asdmdir+'Antenna.xml',\"r\")\n",
    "        statXML = open(asdmdir+'Station.xml',\"r\")\n",
    "        weaXML = open(asdmdir+'Weather.xml',\"r\")\n",
    "        phaseXML = open(asdmdir+'CalPhase.xml',\"r\")\n",
    "        for file in os.listdir(asdmdir):\n",
    "            if \".log\" in file:\n",
    "                log = open(asdmdir+file,\"r\")\n",
    "        '''\n",
    "        # Create all pre-CSV arrays\n",
    "        antArr = np.empty((1,21),dtype='U25')\n",
    "        weaArr = np.empty((1,11),dtype='U25')\n",
    "\n",
    "        # Prepare all input files for looping\n",
    "        ##########\n",
    "        line = antXML.readline()\n",
    "        while \"<ContainerEntity\" not in line:\n",
    "            line = antXML.readline()\n",
    "        ##########\n",
    "        line = statXML.readline()\n",
    "        while \"<ContainerEntity\" not in line:\n",
    "            line = statXML.readline()\n",
    "        ##########\n",
    "        line = weaXML.readline()\n",
    "        while \"<ContainerEntity\" not in line:\n",
    "            line = weaXML.readline()\n",
    "        ##########\n",
    "        line = phaseXML.readline()\n",
    "        while \"<ContainerEntity\" not in line:\n",
    "            line = phaseXML.readline()\n",
    "        ##########\n",
    "        line = log.readline()\n",
    "        while \"Ref.\" not in line:\n",
    "            line = log.readline()\n",
    "        ##########\n",
    "\n",
    "\n",
    "        ########## Antenna.xml Cycling\n",
    "        line = antXML.readline()\n",
    "        while \"</AntennaTable>\" not in line:\n",
    "            antXML.readline()\n",
    "\n",
    "            antRow = np.empty(21,dtype='U25')\n",
    "            antRow[0] = re.sub(r\"<.*?>\", \"\", antXML.readline()).strip() # antname\n",
    "            for i in range(6): line = antXML.readline()\n",
    "            antRow[2] = re.sub(r\"<.*?>\", \"\", antXML.readline()).strip() # statnum\n",
    "            for i in range(2): line = antXML.readline()\n",
    "\n",
    "            antArr = np.vstack((antArr,antRow)) # Add row to antArr\n",
    "\n",
    "        antArr = antArr[1:,:] # Remove first row (consequence of row-adding method)\n",
    "\n",
    "\n",
    "        ########## Station.xml Cycling\n",
    "        row = 0\n",
    "        line = statXML.readline()\n",
    "        while \"</StationTable>\" not in line:\n",
    "            if row < np.shape(antArr)[0]:\n",
    "                statXML.readline()\n",
    "\n",
    "                antArr[row,1] = re.sub(r\"<.*?>\", \"\", statXML.readline()).strip() # padname\n",
    "                line = statXML.readline().split()\n",
    "                for i in range(2,4): antArr[row,i+15] = line[i] # geopos (X,Y)\n",
    "                antArr[row,19] = line[4].rstrip(\"</position>\\n\") # geopos (Z)\n",
    "                for i in range(3): line = statXML.readline()\n",
    "            else:\n",
    "                weaRow = np.empty(11,dtype='U25')\n",
    "                weaRow[1] = re.sub(r\"<.*?>\", \"\", statXML.readline()).strip() # statnum\n",
    "                weaRow[0] = re.sub(r\"<.*?>\", \"\", statXML.readline()).strip() # padname\n",
    "                line = statXML.readline().split()\n",
    "                for i in range(2,4): weaRow[i] = line[i] # geopos (X,Y)\n",
    "                weaRow[4] = line[4].rstrip(\"</position>\\n\") # geopos (Z)\n",
    "                for i in range(3): line = statXML.readline()\n",
    "\n",
    "                weaArr = np.vstack((weaArr,weaRow)) # Add row to weaArr\n",
    "\n",
    "            row += 1\n",
    "\n",
    "        weaArr = weaArr[1:,:] # Remove first row (consequence of row-adding method)\n",
    "\n",
    "\n",
    "        ########## Weather.xml Cycling\n",
    "        tempWeaArr = np.zeros((len(weaants),7),dtype='float')\n",
    "\n",
    "        line = weaXML.readline()\n",
    "        while \"</WeatherTable>\" not in line:\n",
    "            line = weaXML.readline()\n",
    "\n",
    "            temp = np.empty(6,dtype='float')\n",
    "            for i in range(6): temp[i] = re.sub(r\"<.*?>\", \"\", weaXML.readline()).strip() # All weather attributes\n",
    "            statNum = weaXML.readline().lstrip(\"    <stationId>\").rstrip(\"</stationId>\\n\")\n",
    "            for i in range(2): line = weaXML.readline()\n",
    "\n",
    "            \n",
    "            The strategy below is a bit tricky. Since it's tricky adding rows to 3D numpy arrays, I've decided to\n",
    "            implement a sort of working average concept. The idea is that tempWeaArr has len(weaants) rows, each \n",
    "            with 7 columns. These 7 columns are the 6 weather attributes plus the \"number of rows\" so that we can \n",
    "            take the average correctly. For each chunk of weather data for a given station in Weather.xml, the \n",
    "            working average is updated along with the \"number of rows\".\n",
    "            \n",
    "\n",
    "            for i in range(len(weaants)):\n",
    "                if weaArr[i,1] == statNum and temp[0] != 0:\n",
    "                    tempWeaArr[i,:6] = tempWeaArr[i,:6] + temp # Summation portion of \"working average\"\n",
    "                    tempWeaArr[i,6] += 1\n",
    "\n",
    "        for row in range(np.shape(tempWeaArr)[0]):\n",
    "            if tempWeaArr[row,6] != 0:\n",
    "                tempWeaArr[row,:6] = tempWeaArr[row,:6] / tempWeaArr[row,6] # Division portion of \"working average\"\n",
    "\n",
    "        for i in range(len(weaants)):\n",
    "            for j in range(6):\n",
    "                weaArr[i,5:] = tempWeaArr[i,:6]\n",
    "\n",
    "        ########## CalPhase.xml Cycling\n",
    "        line = phaseXML.readline()\n",
    "        while \"<singleAntennaName>\" not in line: line = phaseXML.readline()\n",
    "        line = re.sub(r\"<.*?>\", \"\", line).strip().split()\n",
    "\n",
    "        antNames = []\n",
    "        for i in range(2,int(line[1])+2): antNames.append(line[i][1:-1])\n",
    "\n",
    "        phaseXML = open(uidDir+'CalPhase.xml',\"r\")\n",
    "        phaseData = np.zeros((len(antNames),3),dtype='float')\n",
    "\n",
    "        for i in range(5): line = phaseXML.readline()\n",
    "        while \"</CalPhaseTable>\" not in line:\n",
    "            for i in range(108): phaseXML.readline() # Skips BB_1, BB_2, BB_3, and BB_4 entirely\n",
    "            for i in range(21): phaseXML.readline() # Skips to phaseAnt data within BB_ALL\n",
    "\n",
    "            line = re.sub(r\"<.*?>\", \"\", phaseXML.readline()).strip().split()\n",
    "\n",
    "            \n",
    "            I've decided to adopt the same \"working average\" concept above here, since the data comes in a\n",
    "            similar format.\n",
    "            \n",
    "\n",
    "            # Processing <phaseAnt> data within BB_ALL\n",
    "            temp = line[2]\n",
    "            line = line[3:]\n",
    "            for j in range(2):\n",
    "                for i in range(int(j*len(line)/2),int((j+1)*len(line)/2)):\n",
    "                    if line[i] != 0:\n",
    "                        phaseData[int(i%(len(line)/2)),j] = phaseData[int(i%(len(line)/2)),j] + float(line[i]) # Summation portion of \"working average\"\n",
    "            phaseData[:,2] += 1\n",
    "\n",
    "            for i in range(5): line = phaseXML.readline()\n",
    "\n",
    "        for i in range(2): phaseData[:,i] = phaseData[:,i] / phaseData[:,2] # Division portion of \"working average\"\n",
    "        phaseData = phaseData[:,:2]\n",
    "\n",
    "        antArr[:,3:5] = phaseData[:,:]\n",
    "\n",
    "\n",
    "        ########## .Log Cycling\n",
    "        row = 1\n",
    "        line = log.readline()\n",
    "        while row < np.shape(antArr[:,0])[0]:\n",
    "            line = line.split()\n",
    "            for i in range(3): antArr[row,i+5] = line[2*(i+2)] # poserr (X,Y,Z)\n",
    "            for i in range(2): antArr[row,i+8] = line[2*(i+3)-1][1:-3] # poserr() (X,Y)\n",
    "            antArr[row,10] = line[9][1:-2] # poserr() (Z)\n",
    "            antArr[row,20] = line[12]\n",
    "            line = log.readline().split()\n",
    "            for i in range(3): antArr[row,i+11] = line[2*(i+1)] # newpos (X,Y,Z)\n",
    "            line = log.readline().split()\n",
    "            for i in range(3): antArr[row,i+14] = line[2*(i+1)] # geoerr (X,Y,Z)\n",
    "            for i in range(2): line = log.readline()\n",
    "\n",
    "            row += 1\n",
    "\n",
    "        weaArr[weaArr == \"0.0\"] = np.nan\n",
    "        antArr[antArr == \"0.0\"] = np.nan\n",
    "        antArr[antArr == \"\"] = np.nan\n",
    "        pd.DataFrame(weaArr).to_csv(uidDir+'WeaData.csv', index=None, header=weaArrHeaders) # Export weaArr to WeaData.csv\n",
    "        pd.DataFrame(antArr).to_csv(uidDir+'AntData.csv', index=None, header=antArrHeaders) # Export antArr to AntData.csv\n",
    "'''"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# observation combination"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "done\n"
     ]
    }
   ],
   "source": [
    "antArr = np.empty((len(refants),numObs,23),dtype='U25')\n",
    "weaArr = np.empty((len(weaants),numObs,13),dtype='U25')\n",
    "\n",
    "row = 0\n",
    "for uid in os.listdir(genDir):\n",
    "    if uid[:3] == \"uid\":\n",
    "        uidDir = genDir+uid+'/'\n",
    "        \n",
    "        # Load in antenna and weather station data\n",
    "        antData = pd.read_csv(uidDir+'/AntData.csv')\n",
    "        weaData = pd.read_csv(uidDir+'/WeaData.csv')\n",
    "        antData.index = antData.antname\n",
    "        weaData.index = weaData.padname\n",
    "        \n",
    "        # Extract time from ASDM.xml\n",
    "        asdmXML = open(uidDir+'/ASDM.xml',\"r\")\n",
    "        for i in range(4): line = asdmXML.readline()\n",
    "        time = tc.FormattedTimetoUnix(re.sub(r\"<.*?>\", \"\", line).strip()) # time\n",
    "\n",
    "        # Combine time, uid, and AntData.csv into one place\n",
    "        for ant in range(len(refants)):\n",
    "            antArr[ant,row,:2] = np.array([time,uid],dtype='U25')\n",
    "            if refants[ant] in antData.index:\n",
    "                antArr[ant,row,2:] = antData.loc[refants[ant]].to_numpy()\n",
    "            else: antArr[ant,row,2:] = np.nan\n",
    "\n",
    "        # Combine time, uid, and WeaData.csv into one place\n",
    "        for stat in range(len(weaants)):\n",
    "            weaArr[stat,row,:2] = np.array([time,uid],dtype='U25')\n",
    "            weaArr[stat,row,2:] = weaData.loc[weaants[stat]].to_numpy()\n",
    "\n",
    "        row += 1\n",
    "    \n",
    "# Create new \"offsetdata\" and \"weatherdata\" directories, if they don't already exist\n",
    "if not os.path.isdir(directory+'/'+date+'/offsetdata'):\n",
    "    os.mkdir(directory+'/'+date+'/offsetdata')\n",
    "if not os.path.isdir(directory+'/'+date+'/weatherdata'):\n",
    "    os.mkdir(directory+'/'+date+'/weatherdata')\n",
    "\n",
    "# Export to \"offsetdata\"\n",
    "for i in range(len(refants)): \n",
    "    temp = pd.DataFrame(antArr[i,(antArr[i,:,0].argsort())],columns=['time','uid','antname','padname','statnum','xPhaseAvg','yPhaseAvg','poserrX','poserrY','poserrZ','poserr()X','poserr()Y','poserr()Z','newposX','newposY','newposZ','geoerrX','geoerrY','geoerrZ','geoposX','geoposY','geoposZ','delayrms'])\n",
    "    temp = temp.drop(columns='antname')\n",
    "    pd.DataFrame(temp).to_csv(directory+'/'+date+'/offsetdata/'+refants[i]+'.csv', index=None)\n",
    "\n",
    "# Export to \"weatherdata\"\n",
    "for i in range(len(weaants)): \n",
    "    temp = pd.DataFrame(weaArr[i,(weaArr[i,:,0].argsort())],columns=['time','uid','padname','statnum','geoposX','geoposY','geoposZ','pressure','relHum','temp','windDir','windSpeed','windMax'])\n",
    "    temp = temp.drop(columns='padname')\n",
    "    pd.DataFrame(temp).to_csv(directory+'/'+date+'/weatherdata/'+weaants[i]+'.csv', index=None)\n",
    "    \n",
    "print(\"done\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
